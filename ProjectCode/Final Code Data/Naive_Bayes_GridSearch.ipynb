{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ocoYXkH_TkOW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk import tokenize\n",
        "import numpy as np\n",
        "from sklearn import metrics\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from lexical_diversity import lex_div as ld\n",
        "from nltk.util import ngrams\n",
        "import gensim\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import nltk\n",
        "import os\n",
        "import codecs\n",
        "import re\n",
        "import string\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.util import ngrams\n",
        "from collections import Counter\n",
        "from collections import OrderedDict\n",
        "# import nlp\n",
        "import spacy\n",
        "from textstat.textstat import textstatistics, legacy_round\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "#Using Min Max scaler for NAive bayes so as to bound the values between 0 and 1\n",
        "#Negative values won't work for probability computations\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "#GridSearch for hyperparams tuning and classification_report for generating report after param tuning\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "import en_core_web_sm\n",
        "from sklearn import svm\n",
        "#Naive Bayes from SKLearn\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "nlp = en_core_web_sm.load()\n",
        "\n",
        "#Supress warning in console\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "data = pd.read_csv(\"final_features_without_null_values.csv\",encoding = \"ISO-8859-1\")\n",
        "#For giving relative path\n",
        "from pathlib import Path\n",
        "#base_path = Path(__file__).parent\n",
        "#file_path = (\"final_features_without_null_values.csv\").resolve()\n",
        "#data = pd.read_csv(file_path,encoding=\"ISO-8859-1\")"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-e_QYmXU-lb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        },
        "outputId": "6cc78c00-2882-454f-e564-1de508b7d62a"
      },
      "source": [
        "# Split Train and Test Data\n",
        "y_true = data['class'].values\n",
        "X  = data.iloc[:,:-1]\n",
        "x_train, test_df, y_train, y_test = train_test_split(X, y_true, stratify = y_true, test_size = 0.2)\n",
        "df_y_train = pd.DataFrame(y_train, columns=['class'])\n",
        "df_y_test = pd.DataFrame(y_test, columns=['class'])\n",
        "# train_df, cv_df, y_train, y_cv = train_test_split(x_train, y_train, stratify = y_train, test_size = 0.2)\n",
        "\n",
        "print(\"Number of samples in training data :\", x_train.shape[0])\n",
        "# print(\"Number of samples in validation data :\", cv_df.shape[0])\n",
        "print(\"Number of samples in test data :\", test_df.shape[0])\n",
        "\n",
        "train_class_distribution = df_y_train['class'].value_counts().sort_index()\n",
        "# cv_class_distribution = cv_df['class'].value_counts().sort_index()\n",
        "test_class_distribution = df_y_test['class'].value_counts().sort_index()\n",
        "\n",
        "print(\"\\ntraining distribution:\\n\\n\", train_class_distribution)\n",
        "# print(\"\\ncv distribution: \\n\\n\", cv_class_distribution)\n",
        "print(\"\\ntest distribution: \\n\\n\", test_class_distribution)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of samples in training data : 795\n",
            "Number of samples in test data : 199\n",
            "\n",
            "training distribution:\n",
            "\n",
            " 0      2\n",
            "1      4\n",
            "2     89\n",
            "3      5\n",
            "4      5\n",
            "5    633\n",
            "6     14\n",
            "7     29\n",
            "8     14\n",
            "Name: class, dtype: int64\n",
            "\n",
            "test distribution: \n",
            "\n",
            " 1      1\n",
            "2     22\n",
            "3      1\n",
            "4      1\n",
            "5    159\n",
            "6      4\n",
            "7      7\n",
            "8      4\n",
            "Name: class, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzQOmc7MX0IQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "30b9154a-85f5-46cc-a5cc-435db215d35e"
      },
      "source": [
        "scaler = MinMaxScaler()\n",
        "train_df = scaler.fit_transform(x_train)\n",
        "test_df = scaler.fit_transform(test_df)\n",
        "\n",
        "\n",
        "# Alpha=Smoothening parameter(0 for no smoothening)\n",
        "# Other hyperparams for naive bayes fit_prior & class prior\n",
        "# If we know class prior set fit prior to yes and define class prior, Now since we don't know we are going with uniform prior for classes\n",
        "clf = MultinomialNB(alpha=.45)\n",
        "clf.fit(train_df, y_train)\n",
        "pred = clf.predict(test_df)\n",
        "\n",
        "print('*******************F1 Score and Accuracy*****************************')\n",
        "print('F1 Score: ',metrics.f1_score(y_test, pred, average='macro'))\n",
        "print('Precision Score: ', metrics.precision_score(y_test, pred, average='macro'))\n",
        "print('Recall Score: ', metrics.recall_score(y_test, pred, average='macro'))\n",
        "print('Accuracy: ', metrics.accuracy_score(y_test, pred))\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "*******************F1 Score and Accuracy*****************************\n",
            "F1 Score:  0.11103351955307263\n",
            "Precision Score:  0.09987437185929648\n",
            "Recall Score:  0.125\n",
            "Accuracy:  0.7989949748743719\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1uyWSFbYI3w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 849
        },
        "outputId": "0c5bf06a-3903-4e35-8e27-a3c35025e528"
      },
      "source": [
        "#Tune Hyperparams\n",
        "# Set the parameters using GridSearchCV\n",
        "tuned_parameters = [{'alpha': [0.40,0.25,0.45,0.55]}]\n",
        "scores = ['precision', 'recall','f1']\n",
        "\n",
        "for score in scores:\n",
        "\tprint(\"# Tuning hyper-parameters for %s\" % score)\n",
        "\tclf = GridSearchCV(MultinomialNB(), tuned_parameters, scoring='%s_macro' % score)\n",
        "\tclf.fit(train_df, y_train)\n",
        "\n",
        "\tprint(\"Best parameters set found on development set:\")\n",
        "\tprint(clf.best_params_)\n",
        "\tprint(\"Grid scores on development set:\")\n",
        "\tmeans = clf.cv_results_['mean_test_score']\n",
        "\tstds = clf.cv_results_['std_test_score']\n",
        "\tfor mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
        "\t\tprint(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))\n",
        "\tprint(\"Detailed classification report:\")\n",
        "\tprint(\"The model is trained on the full development set.\")\n",
        "\tprint(\"The scores are computed on the full evaluation set.\")\n",
        "\ty_true, y_pred = y_test, clf.predict(test_df)\n",
        "\n",
        "print(classification_report(y_true, y_pred))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# Tuning hyper-parameters for precision\n",
            "Best parameters set found on development set:\n",
            "{'alpha': 0.4}\n",
            "Grid scores on development set:\n",
            "0.097 (+/-0.009) for {'alpha': 0.4}\n",
            "0.097 (+/-0.009) for {'alpha': 0.25}\n",
            "0.097 (+/-0.009) for {'alpha': 0.45}\n",
            "0.097 (+/-0.009) for {'alpha': 0.55}\n",
            "Detailed classification report:\n",
            "The model is trained on the full development set.\n",
            "The scores are computed on the full evaluation set.\n",
            "# Tuning hyper-parameters for recall\n",
            "Best parameters set found on development set:\n",
            "{'alpha': 0.4}\n",
            "Grid scores on development set:\n",
            "0.122 (+/-0.011) for {'alpha': 0.4}\n",
            "0.122 (+/-0.011) for {'alpha': 0.25}\n",
            "0.122 (+/-0.011) for {'alpha': 0.45}\n",
            "0.122 (+/-0.011) for {'alpha': 0.55}\n",
            "Detailed classification report:\n",
            "The model is trained on the full development set.\n",
            "The scores are computed on the full evaluation set.\n",
            "# Tuning hyper-parameters for f1\n",
            "Best parameters set found on development set:\n",
            "{'alpha': 0.4}\n",
            "Grid scores on development set:\n",
            "0.108 (+/-0.010) for {'alpha': 0.4}\n",
            "0.108 (+/-0.010) for {'alpha': 0.25}\n",
            "0.108 (+/-0.010) for {'alpha': 0.45}\n",
            "0.108 (+/-0.010) for {'alpha': 0.55}\n",
            "Detailed classification report:\n",
            "The model is trained on the full development set.\n",
            "The scores are computed on the full evaluation set.\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.00      0.00      0.00         1\n",
            "           2       0.00      0.00      0.00        22\n",
            "           3       0.00      0.00      0.00         1\n",
            "           4       0.00      0.00      0.00         1\n",
            "           5       0.80      1.00      0.89       159\n",
            "           6       0.00      0.00      0.00         4\n",
            "           7       0.00      0.00      0.00         7\n",
            "           8       0.00      0.00      0.00         4\n",
            "\n",
            "    accuracy                           0.80       199\n",
            "   macro avg       0.10      0.12      0.11       199\n",
            "weighted avg       0.64      0.80      0.71       199\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y2yqI5FjYqu_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "c0836c91-db2a-4794-f00a-649d23544cbb"
      },
      "source": [
        "#So fixed alpha=0.45 as smoothening parameter to naive bayes and performed classification\n",
        "clf = MultinomialNB(alpha=.45)\n",
        "clf.fit(train_df, y_train)\n",
        "pred = clf.predict(test_df)\n",
        "\n",
        "print('*******************F1 Score and Accuracy*****************************')\n",
        "print('F1 Score: ',metrics.f1_score(y_test, pred, average='macro'))\n",
        "print('Precision Score: ', metrics.precision_score(y_test, pred, average='macro'))\n",
        "print('Recall Score: ', metrics.recall_score(y_test, pred, average='macro'))\n",
        "print('Accuracy: ', metrics.accuracy_score(y_test, pred))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "*******************F1 Score and Accuracy*****************************\n",
            "F1 Score:  0.11103351955307263\n",
            "Precision Score:  0.09987437185929648\n",
            "Recall Score:  0.125\n",
            "Accuracy:  0.7989949748743719\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}