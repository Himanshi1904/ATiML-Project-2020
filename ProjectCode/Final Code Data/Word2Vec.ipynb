{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_CuBCglIO45",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "7b5cd077-878f-4420-c4e1-d5087d79df7a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MjTD5mnGLKt2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os \n",
        "os.chdir(\"/content/drive/My Drive/Gutenberg_books\")\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5KSmmwTLq84",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_score, train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8C5zglbHW3f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "a728bd90-1aaa-4c4f-bf9c-088c01f2b4e9"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TIB-an7kHjuG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "22bac09f-870e-41e0-b2be-2fdd97e512d7"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pxe_DpQbNFxy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Read the csv file into pandas dataframe\n",
        "data = pd.read_csv(\"master996.csv\",encoding = \"ISO-8859-1\")\n",
        "\n",
        "#Replace book id with the actual name present in html so as to iterate through html files\n",
        "data['book_id'] = data['book_id'].str.replace('.epub', '-content.html', case = False)\n",
        "book_id_array = data['book_id'].to_numpy()\n",
        "#print(book_id_array[0])\n",
        "\n",
        "genre = ['guten_genre']"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qb3408qfPHM6",
        "colab": {}
      },
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_score, train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Read the csv file into pandas dataframe\n",
        "data = pd.read_csv(\"master996.csv\",encoding = \"ISO-8859-1\")\n",
        "\n",
        "#Replace book id with the actual name present in html so as to iterate through html files\n",
        "data['book_id'] = data['book_id'].str.replace('.epub', '-content.html', case = False)\n",
        "book_id_array = data['book_id'].to_numpy()\n",
        "#print(book_id_array[0])\n",
        "\n",
        "genre = ['guten_genre']\n",
        "\n",
        "#Convert each genre of data dataframe into numbers\n",
        "for x in genre:\n",
        "    le = LabelEncoder()\n",
        "    le.fit(list(data[x].values))\n",
        "    data[x] = le.transform(list(data[x]))\n",
        "print('******************Dataframe after converting Genre as numbers**********************')\n",
        "print(data)\n",
        "\n",
        "wordArray = []\n",
        "index = 0\n",
        "\n",
        "#Iterate through each .html files and read the contents and append to our exisitng dataframe\n",
        "while index < len(book_id_array):\n",
        "\t#Open the HTML file abd read the contents for tokenizing\n",
        "\t#Replace the path with the folder where html files are present\n",
        "\t#HTMLfile = open('E:\\\\OVGU\\\\Sem2_Summer2020\\\\Subjects\\\\ATML\\\\Semester_Project\\\\starter\\\\Gutenberg_English_Fiction_1k\\\\Gutenberg_19th_century_English_Fiction\\\\'+book_id_array[index],'r',encoding='utf-8')\n",
        "\tHTMLfile = open('/content/drive/My Drive/Gutenberg_books/Gutenberg_19th_century_English_Fiction/'+book_id_array[index],'r',encoding='utf-8')\n",
        "\n",
        "\tcontent = HTMLfile.read()\n",
        "\tr = re.compile('<.*?>')\n",
        "\tcontent_removed_tags = re.sub(r, '', content)\n",
        "\n",
        "\t#Pick pre-defineds Stop words from nltk lib\n",
        "\tstop_words = list(stopwords.words('english'))\n",
        "\n",
        "\t# Tokenize the text\n",
        "\ttokens = word_tokenize(content_removed_tags)\n",
        "\t# Convert into lower case\n",
        "\ttokens = [w.lower() for w in tokens]\n",
        "\tprint('Document ',index,':')\n",
        "\tprint('After Tokenizing: ',len(tokens))\n",
        "\n",
        "\t#Remove non alphabetic words/Removing punctuations\n",
        "\twords = [word for word in tokens if word.isalpha()]\n",
        "\tprint('After Removing Punctuations: ',len(words))\n",
        "\t#Removing Stopwords\n",
        "\twords = [w for w in words if not w in stop_words]\n",
        "\tprint('After Removing Stopwords: ',len(words))\n",
        "\t\n",
        "\twordArray.insert(index,words)\n",
        "\tindex = index+1\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvPjlYIiN4U2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        },
        "outputId": "43650fa9-5a15-4ce8-dc19-f6756b2ae100"
      },
      "source": [
        "print(len(wordArray))\n",
        "\n",
        "data['tokens'] = wordArray\n",
        "#Convert the list into strings, column should have tokens seperated by space\n",
        "data['list_string'] = data['tokens'].apply(lambda x: ' '.join(map(str, x)))\n",
        "\n",
        "print('******************Dataframe after appending Tokens**********************')\n",
        "#Dataframe after appending the tokens of respective books into data['list_string']\n",
        "print(data)\n",
        "\n",
        "vectorizer = CountVectorizer()\n",
        "vectors = vectorizer.fit_transform(data['list_string'])\n",
        "print('************************Vectors Shape*******************************')\n",
        "print(vectors.shape)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(vectors, data['guten_genre'], test_size=0.3)\n",
        "print('*******************Train and Test Set Size**************************')\n",
        "print (X_train.shape)\n",
        "print (y_train.shape)\n",
        "print (X_test.shape)\n",
        "print (y_test.shape)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "996\n",
            "******************Dataframe after appending Tokens**********************\n",
            "                                             Book_Name  ...                                        list_string\n",
            "0    The Mystery of the Boule Cabinet: A Detective ...  ...  detective story hello said took receiver desk ...\n",
            "1                                            The Pupil  ...  edition first published text follows definitiv...\n",
            "2                                       At Love's Cost  ...  moment never fully realised great ass man thin...\n",
            "3                               The Heart of the Range  ...  rider golden bar hidden trails lynch lawyers o...\n",
            "4                          The Worshipper of the Image  ...  worshipper image evening wood still dreaming b...\n",
            "..                                                 ...  ...                                                ...\n",
            "991                                  David Copperfield  ...  find easy get sufficiently far away book first...\n",
            "992                                         Hard Times  ...  one thing needful murdering innocents loophole...\n",
            "993                          Memoirs of Shelock Holmes  ...  afraid watson shall go said holmes sat togethe...\n",
            "994                    The Mysterious Affair at Styles  ...  intense interest aroused public known time sty...\n",
            "995                               A Tale of Two Cities  ...  book first recalled life period ii mail iii ni...\n",
            "\n",
            "[996 rows x 6 columns]\n",
            "************************Vectors Shape*******************************\n",
            "(996, 157616)\n",
            "*******************Train and Test Set Size**************************\n",
            "(697, 157616)\n",
            "(697,)\n",
            "(299, 157616)\n",
            "(299,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "khkELBiYIVZH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "outputId": "8df370ed-ccdd-49d9-d6fd-c6b157cae0a8"
      },
      "source": [
        "clf = MultinomialNB(alpha=.45)\n",
        "clf.fit(X_train, y_train)\n",
        "pred = clf.predict(X_test)\n",
        "\n",
        "print('*******************F1 Score and Accuracy*****************************')\n",
        "print('F1 Score: ',metrics.f1_score(y_test, pred, average='macro'))\n",
        "print('Precision Score: ', metrics.precision_score(y_test, pred, average='macro'))\n",
        "print('Recall Score: ', metrics.recall_score(y_test, pred, average='macro'))\n",
        "print('Accuracy: ', metrics.accuracy_score(y_test, pred))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "*******************F1 Score and Accuracy*****************************\n",
            "F1 Score:  0.36980426183012394\n",
            "Precision Score:  0.3475478636721743\n",
            "Recall Score:  0.4063309571784148\n",
            "Accuracy:  0.8294314381270903\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}